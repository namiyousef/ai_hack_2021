{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Hack 21\n",
    "\n",
    "## Boston Housing Market Challenge\n",
    "\n",
    "**Challenge Description**\n",
    "\n",
    "First studied by Harrison and Rubinfeld (1978), the Boston Housing dataset has been extensively used in testing new machine learning models against existing benchmarks. It is a small dataset with only 506 observations, but is inherently interesting because a lot of things could be studied about this dataset. For this challenge, you are free to pose your own studies and encouraged to use alternative datasets.\n",
    "\n",
    "\n",
    "You have two options for this challenge. You can either use the housing prices as a response variable and conduct a regression analysis, or focus on the nitrous oxide level and perform a classification task. **You only need to choose one of these two options for your study.** You need not to be comprehensive; the depth of analysis is more important than breaths of the questions posed. You can base your analysis on the available datasets as well as any supplementary datasets you may find.\n",
    "\n",
    "You may explore one of the sample questions below, or come up with your own variation. Creativity in formulating your own questions is strongly encouraged, although this should not compromise the depth, precision and rigour of your analysis, which will be key performance indicators during assessment.\n",
    "\n",
    "**Data**\n",
    "\n",
    "The original Boston housing dataset can be accessed via the sklearn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "boston_load = datasets.load_boston() boston = pd.DataFrame(boston_load.data, columns=boston_load.feature_names)\n",
    "boston['MEDV'] = boston_load.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A corrected version with town names and spatial information is also available here, which is augmented with longitude and latitude of the observations and corrected for the censoring error. In particular, the censoring error refers to the fact that in the original dataset, the house price is capped at USD 50,000, with values higher than this number set to USD 50,000 (see the description on the page for the corrected dataset: [Ref 1], and also the _Note_ section of this page for the original data: [Ref 2]).\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[Ref 1] https://nowosad.github.io/spData/reference/boston.html\n",
    "\n",
    "[Ref 2] https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Questions**:\n",
    "\n",
    "Regression:\n",
    "\n",
    "    [1]. Amongst the given attributes, can you identify any interesting quantities that are correlated with the house price, and uncover their statistical associations? Can you explain your findings?\n",
    "\n",
    "    [2]. Does the house price show any spatial heterogeneity across the towns?\n",
    "    You may find the Python library *geopandas* and the *GeoJSON* shapefiles helpful for visualization.\n",
    "\n",
    "    [3]. A recent study in the Journal of the American Statistical Association (JASA) studied the causal effects of geographical boundaries for house prices in New York City. Can you conduct a similar study?\n",
    "\n",
    "\n",
    "Classification:\n",
    "\n",
    "    [1]. Is the nitrous oxide level correlated with any of the explanatory variables? Is this relationship causal?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**You are reminded that you only need to choose one of regression or classification for your analysis.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips and Suggestions**:\n",
    "\n",
    "The following workflow may help:\n",
    "\n",
    "[1]. Clean the dataset\n",
    "    - Impute missing data (if any)\n",
    "    - Do some feature engineering e.g. PCA/t-SNE\n",
    "    \n",
    "[2]. Visualise linear correlations.\n",
    "    - Can you find any? Compute correlation coefficients\n",
    "    \n",
    "[3]. Visualise target distribution\n",
    "\n",
    "[4]. Regress/classify on all features\n",
    "    - Report in sample and out of sample loss\n",
    "    - Report estimated model parameters\n",
    "    - Is spatial adjacency a key information too? How do you add this into your model?\n",
    "    \n",
    "[5]. Do feature selection/model selection\n",
    "\n",
    "[6]. Gather your conclusions. What are their implications on economy/policy making?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
